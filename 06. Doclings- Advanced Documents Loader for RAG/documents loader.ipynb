{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich MarkDown with Images Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## hide warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "import base64\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# model = ChatOllama(model=\"llama3.2-vision\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "system_message = SystemMessage(\"\"\"\n",
    "                Extract detailed financial information from the provided image. Start by identifying the company name, document title, and any relevant details from the header and footer.\n",
    "\n",
    "                Ensure to:\n",
    "                    - Thoroughly extract all financial figures and metrics mentioned, such as revenue, profit, assets, liabilities, etc.\n",
    "                    - Explain the financial data with technical details, including any relevant financial terminology or calculation methods.\n",
    "                    - Summarize any regulatory or legal information provided in the document.\n",
    "                \n",
    "                Provide a complete and detailed description of the image in the form of table if possible.\n",
    "                       \"\"\")\n",
    "\n",
    "def get_image_description(image_data_path, image_urls, cleaned_content):\n",
    "    images_data = []\n",
    "    for url in image_urls:\n",
    "        url = f\"{image_data_path}/{url}\".replace(\"%5C\", \"/\")\n",
    "        with open(url, \"rb\") as f:\n",
    "            img_base64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "            img_dict = {\"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/{url.split('.')[-1]};base64,{img_base64}\"}}\n",
    "            \n",
    "            images_data.append(img_dict)\n",
    "\n",
    "    text = f\"\"\"Here is some reference content for the image. You need to ensure the generated image description fits into the given context.\n",
    "                Do not write any preamble or explanation other than asked in the task described.\n",
    "\n",
    "                ### Content to Get The Idea What This Image Is About:\n",
    "                {cleaned_content}\n",
    "\n",
    "                Generate a detailed description of the image. \n",
    "                Ensure that the description is comprehensive and no important data is missed.\n",
    "                ### Image Description:\"\"\"\n",
    "    \n",
    "    text_message = {\"type\": \"text\", \"text\": text}\n",
    "    \n",
    "    final_message = [text_message] + images_data\n",
    "\n",
    "    message = HumanMessage(content=final_message)\n",
    "\n",
    "    # ResponseError: vision model only supports a single image per message\n",
    "    # in case of Ollama Model, LLAMA3.2 Vision\n",
    "    # message = HumanMessage(content=[text_message, images_data[0]])               \n",
    "    \n",
    "    response = model.invoke([system_message, message])\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doclings \n",
    "- ðŸ—‚ï¸ Reads popular document formats (PDF, DOCX, PPTX, XLSX, Images, HTML, AsciiDoc & Markdown) and exports to HTML, Markdown and JSON (with embedded and referenced images)\n",
    "- ðŸ“‘ Advanced PDF document understanding including page layout, reading order & table structures\n",
    "- ðŸ§© Unified, expressive DoclingDocument representation format\n",
    "- ðŸ¤– Plug-and-play integrations incl. LangChain, LlamaIndex, Crew AI & Haystack for agentic AI\n",
    "- ðŸ” OCR support for scanned PDFs\n",
    "- ðŸ’» Simple and convenient CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/DS4SD/docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load the custom kernel for multi-scale deformable attention: Command '['where', 'cl']' returned non-zero exit status 1.\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/Earnings-Presentation-Q3-2024-with-image-refs.md'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 32\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m md_filename\n\u001b[0;32m     31\u001b[0m input_doc_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m00 Dataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdocs\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfacebook\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEarnings-Presentation-Q3-2024.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 32\u001b[0m md_filename \u001b[38;5;241m=\u001b[39m \u001b[43mget_markdown_without_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_doc_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m md_filename\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# docs\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m, in \u001b[0;36mget_markdown_without_figure\u001b[1;34m(input_doc_path, target_dir)\u001b[0m\n\u001b[0;32m     21\u001b[0m md_filename \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-with-image-refs.md\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# write markdown to file\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmd_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     25\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(docs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content)\n\u001b[0;32m     26\u001b[0m     f\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/Earnings-Presentation-Q3-2024-with-image-refs.md'"
     ]
    }
   ],
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "\n",
    "# import Path\n",
    "from pathlib import Path\n",
    "\n",
    "FILE_PATH = r\"..\\00 Dataset\\docs\\facebook\\Meta-09-30-2024-Exhibit-99-1_FINAL.pdf\"\n",
    "FILE_PATH = r\"..\\00 Dataset\\docs\\facebook\\Downloadable-BS-Q3-24.xlsx\"\n",
    "# FILE_PATH = \"https://pdfobject.com/pdf/sample.pdf\"\n",
    "\n",
    "# get markdown of the files which don't have any figure\n",
    "def get_markdown_without_figure(input_doc_path, target_dir):\n",
    "    loader = DoclingLoader(file_path=input_doc_path,\n",
    "                           export_type=ExportType.MARKDOWN)\n",
    "\n",
    "    docs = loader.load()\n",
    "\n",
    "    # doc file name\n",
    "    doc_filename = Path(input_doc_path).stem\n",
    "\n",
    "    md_filename =  f\"{target_dir}/{doc_filename}-with-image-refs.md\"\n",
    "\n",
    "    # write markdown to file\n",
    "    with open(md_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(docs[0].page_content)\n",
    "        f.close()\n",
    "\n",
    "    return md_filename\n",
    "\n",
    "\n",
    "input_doc_path = r\"..\\00 Dataset\\docs\\facebook\\Earnings-Presentation-Q3-2024.pdf\"\n",
    "md_filename = get_markdown_without_figure(input_doc_path, 'output')\n",
    "\n",
    "md_filename\n",
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF to MarkDown with Images and Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'docling_parse.pdf_parsers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocling_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageRefMode, PictureItem, TableItem\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatamodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline_options\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PdfPipelineOptions\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_converter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocumentConverter, PdfFormatOption\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatamodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputFormat\n\u001b[0;32m      8\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\laxmi\\anaconda3\\envs\\ml\\lib\\site-packages\\docling\\document_converter.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabstract_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AbstractDocumentBackend\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masciidoc_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsciiDocBackend\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocling_parse_v2_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DoclingParseV2DocumentBackend\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhtml_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTMLDocumentBackend\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmd_backend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MarkdownDocumentBackend\n",
      "File \u001b[1;32mc:\\Users\\laxmi\\anaconda3\\envs\\ml\\lib\\site-packages\\docling\\backend\\docling_parse_v2_backend.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpypdfium2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpdfium\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocling_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BoundingBox, CoordOrigin\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocling_parse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pdf_parser_v2\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageDraw\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpypdfium2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PdfPage\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'docling_parse.pdf_parsers'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from docling_core.types.doc import ImageRefMode, PictureItem, TableItem\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "\n",
    "_log = logging.getLogger(__name__)\n",
    "IMAGE_RESOLUTION_SCALE = 2.0\n",
    "\n",
    "def get_pdf_markdown(input_doc_path, target_dir):\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    input_doc_path = Path(input_doc_path)  # Ensure it's a Path object\n",
    "    target_dir = Path(target_dir)  # Ensure it's a Path object\n",
    "    output_dir = Path(\"scratch\")  # Intermediate directory for storing images\n",
    "\n",
    "    # Configure the pipeline options\n",
    "    pipeline_options = PdfPipelineOptions()\n",
    "    pipeline_options.images_scale = IMAGE_RESOLUTION_SCALE\n",
    "    pipeline_options.generate_page_images = True\n",
    "    pipeline_options.generate_picture_images = True\n",
    "\n",
    "    # Initialize the document converter\n",
    "    doc_converter = DocumentConverter(\n",
    "        format_options={\n",
    "            InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Convert the input PDF document\n",
    "    conv_res = doc_converter.convert(input_doc_path)\n",
    "\n",
    "    # Ensure the output directories exist\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    doc_filename = conv_res.input.file.stem\n",
    "\n",
    "    # Save page images\n",
    "    for page_no, page in conv_res.document.pages.items():\n",
    "        page_image_filename = output_dir / f\"{doc_filename}-{page_no}.png\"\n",
    "        with page_image_filename.open(\"wb\") as fp:\n",
    "            page.image.pil_image.save(fp, format=\"PNG\")\n",
    "\n",
    "    # Save images of figures and tables\n",
    "    table_counter = 0\n",
    "    picture_counter = 0\n",
    "    for element, _level in conv_res.document.iterate_items():\n",
    "        if isinstance(element, TableItem):\n",
    "            table_counter += 1\n",
    "            element_image_filename = (\n",
    "                output_dir / f\"{doc_filename}-table-{table_counter}.png\"\n",
    "            )\n",
    "            with element_image_filename.open(\"wb\") as fp:\n",
    "                element.get_image(conv_res.document).save(fp, \"PNG\")\n",
    "\n",
    "        if isinstance(element, PictureItem):\n",
    "            picture_counter += 1\n",
    "            element_image_filename = (\n",
    "                output_dir / f\"{doc_filename}-picture-{picture_counter}.png\"\n",
    "            )\n",
    "            with element_image_filename.open(\"wb\") as fp:\n",
    "                element.get_image(conv_res.document).save(fp, \"PNG\")\n",
    "\n",
    "    # Save markdown with externally referenced pictures\n",
    "    md_filename = target_dir / f\"{doc_filename}-with-image-refs.md\"\n",
    "    conv_res.document.save_as_markdown(md_filename, image_mode=ImageRefMode.REFERENCED)\n",
    "\n",
    "    return md_filename\n",
    "\n",
    "# # Usage example\n",
    "# input_doc_path = r\"..\\00 Dataset\\docs\\facebook\\Earnings-Presentation-Q3-2024.pdf\"\n",
    "# md_filename = get_pdf_markdown(input_doc_path, target_dir=\"output\")\n",
    "# print(md_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MarkDown Splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter, MarkdownTextSplitter\n",
    "\n",
    "# md_filename = r\"scratch\\Earnings-Presentation-Q3-2024-with-image-refs.md\"\n",
    "\n",
    "def get_markdown_splits(md_filename):\n",
    "    with open(md_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        markdown_content = f.read()\n",
    "\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "    ]\n",
    "\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on, strip_headers=False)\n",
    "    md_header_splits = markdown_splitter.split_text(markdown_content)\n",
    "\n",
    "    return md_header_splits\n",
    "\n",
    "md_header_splits = get_markdown_splits(md_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_image_urls_and_clean_content(page_content):\n",
    "    # Define the regex pattern to match image URLs\n",
    "    pattern = r\"!\\[Image\\]\\(([^)]+)\\)\"\n",
    "\n",
    "    # Find all matches in the page content\n",
    "    image_urls = re.findall(pattern, page_content)\n",
    "\n",
    "    # Remove all matched image URLs from the content\n",
    "    cleaned_content = re.sub(pattern, \"\", page_content)\n",
    "\n",
    "    return image_urls, cleaned_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000000_3db7e1eab3213fbdaaf83be4c917fbb9fd97bdf42a5033bd7e7e4df4b53f7b18.png']\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000001_278dad5e9c44f5552629e781407508746b2c8c43e8597f0a69705fe8f19aa660.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000002_f3182f98eee364a6902eebd1c2cbf3ad411e606cf6d9a3e4fb0a07d2f3416e71.png']\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000003_7a5af1bd15760003c9cd20a1f0ac84b7eb0585e9c23c8d401c7e4a3226887e25.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000004_424e40f9e79523cd2b70fb5344a886a7f916bf23ed25745431de3dcabb3a9134.png']\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000005_278dad5e9c44f5552629e781407508746b2c8c43e8597f0a69705fe8f19aa660.png']\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000006_dee327b9119ef6ee2940999dc13e68a8c93145e5d96b82e0461dfa7b71598c73.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000007_c7cb5242c17e44d54b0f9cc654d295579195c561d856168fe0663ee6710fdd06.png']\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000008_dee327b9119ef6ee2940999dc13e68a8c93145e5d96b82e0461dfa7b71598c73.png']\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000009_f85552109ed0a8cb32bf30d05db7be9394370217b99bb7fc069dc269f06d4e31.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000010_278dad5e9c44f5552629e781407508746b2c8c43e8597f0a69705fe8f19aa660.png']\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000011_b6da5accc28d9d241fe64d0531855f295258e6eb478e83f551811f29b9cc2334.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000012_3dbd6ce9176178bbe19bdce419dec3d6aa2c7bdcc97a33ceca26515d3c6317bf.png']\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000013_f2250e6474c3402323412b96a68692489027330905f02ff73358bf5ba9245edf.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000014_6541cfc816f64515a4fc272d7d9e768bee8742845b5641308e23e3f333ae86e2.png']\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000015_b38533143e867d40a45b28680284201d641d46c933fd05b19a2f1b7b6933c0b4.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000016_278dad5e9c44f5552629e781407508746b2c8c43e8597f0a69705fe8f19aa660.png']\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000017_278dad5e9c44f5552629e781407508746b2c8c43e8597f0a69705fe8f19aa660.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000018_a97f7ab741517b759207bb72675c7c3fb62ab12d825ed8bf27d15883e7a2a20d.png']\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000019_d0331d45d03fb943b800e868ada67b63bec57d8f5dd8a8c145d11e9f9f95c293.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000020_a213f8d2d6e7a118e90be891e5d06561645b514797c7f596d6e9e1a32421981e.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000021_b879d51a8e176ee4e872be96173487040d33e3dd6d70a78b695fa698b7b13199.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000022_f5594792ca13a015a0338afcbe240930329eea556394c2c208c4ec4397b1a7d4.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000023_b30f9adff3ec6c5d729f060293ec45b08f5f6b846d4a0fd52bd8e32d50f3848d.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000024_dee327b9119ef6ee2940999dc13e68a8c93145e5d96b82e0461dfa7b71598c73.png']\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000025_41715a006d333b722e233f87005e3dca2fc4acace1efa08db044b49b3db6447c.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000026_4f6a5573d20b3c2a38d819134250fa02bea2811cf29a59e9569845c27467d956.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000027_b6cc85d6ea3ebe02c87a01dae9b39805ed189fb8deebb1398ccbbc31ee516a6d.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000028_bc90987056a214c87c35b505e9157c0c9a1061768b16eea20ab9943fc428efb7.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000029_5e9251d796417c096e71a421be2b4be634a243736edae62cc1bcd690ece29c85.png', 'Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000030_bfc82afd96c94336e0fe98bc6950ac5a226e0826ca3f4ce488897cda70b65b6f.png']\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000031_61331cf29cbe41e0cfd7585af316c8f4a55b1ab6ef528e0d2dfc9640cb8022a5.png']\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000032_fc1e32a9faebdcec75dc7acb7f32b5bc5fafd2b6681eac5f0e43abad585bd063.png']\n",
      "Image URLs: []\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000033_34a3fafa6be647cb65ed649fc2257054f06cba213a04887be094897b444badcf.png']\n",
      "Image URLs: []\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000034_34a3fafa6be647cb65ed649fc2257054f06cba213a04887be094897b444badcf.png']\n",
      "Image URLs: []\n",
      "Image URLs: ['Earnings-Presentation-Q3-2024-with-image-refs_artifacts%5Cimage_000035_1d0090d2a602b18b054d6d31be46f4fa66c6333f8b3e4ce0a1f93de3d7231ec8.png']\n"
     ]
    }
   ],
   "source": [
    "for page in md_header_splits:\n",
    "    # print(f\"Header: {page.metadata}\")\n",
    "    # print(f\"Content: {page.page_content}\")\n",
    "    # Extract image URLs from the page content\n",
    "    image_urls, cleaned_content = extract_image_urls_and_clean_content(page.page_content)\n",
    "    print(f\"Image URLs: {image_urls}\")\n",
    "    # print(f\"Cleaned Content: {cleaned_content}\")\n",
    "    # print(\"\\n\")\n",
    "\n",
    "# md_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich MarkDown with Images Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "def enrich_document_with_image(md_header_splits):\n",
    "    documents = []\n",
    "    for page in md_header_splits:\n",
    "        image_urls, cleaned_content = extract_image_urls_and_clean_content(page.page_content)\n",
    "        # read image from file\n",
    "        \n",
    "        image_data_path = \"scratch\"\n",
    "        image_description = get_image_description(image_data_path, image_urls, cleaned_content)\n",
    "            \n",
    "        \n",
    "        merged_content = cleaned_content + \"\\n\\nExtracted Image Description:\\n\" + image_description\n",
    "\n",
    "        documents.append(merged_content)\n",
    "\n",
    "        # print(\"page: \", page.metadata)\n",
    "        # print(\"response: \", image_description)\n",
    "        # print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "    enriched_content = \"\\n\\n\".join(documents)\n",
    "\n",
    "    return enriched_content\n",
    "\n",
    "enriched_content = enrich_document_with_image(md_header_splits)\n",
    "\n",
    "with open(\"enriched_content.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(enriched_content)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Entire Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:docling.document_converter:Going to convert document batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n",
      "Could not load the custom kernel for multi-scale deformable attention: DLL load failed while importing MultiScaleDeformableAttention: The specified module could not be found.\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.pipeline.base_pipeline:Processing document Earnings-Presentation-Q3-2024.pdf\n",
      "INFO:docling.document_converter:Finished converting document Earnings-Presentation-Q3-2024.pdf in 29.34 sec.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "input_doc_path = r\"..\\00 Dataset\\docs\\facebook\\Earnings-Presentation-Q3-2024.pdf\"\n",
    "md_filename = get_pdf_markdown(input_doc_path, 'output')\n",
    "\n",
    "md_header_splits = get_markdown_splits(md_filename)\n",
    "\n",
    "enriched_content = enrich_document_with_image(md_header_splits)\n",
    "\n",
    "with open(\"enriched_content.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(enriched_content)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ..\\00 Dataset\\docs\\llm_paper.pdf\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_pdf_markdown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m input_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../00 Dataset/docs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../00 Dataset/markdown\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 38\u001b[0m \u001b[43mprocess_and_enrich_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m, in \u001b[0;36mprocess_and_enrich_documents\u001b[1;34m(input_dir, output_dir)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_pdf_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Step 1: Convert PDF to Markdown\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m md_filename \u001b[38;5;241m=\u001b[39m \u001b[43mget_pdf_markdown\u001b[49m(input_pdf_path, target_dir)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Step 2: Split the Markdown content (assume method available)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m md_header_splits \u001b[38;5;241m=\u001b[39m get_markdown_splits(md_filename)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_pdf_markdown' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def process_and_enrich_documents(input_dir, output_dir):\n",
    "\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        relative_path = Path(root).relative_to(input_dir)\n",
    "        target_dir = output_dir / relative_path\n",
    "        target_dir.mkdir(parents=True, exist_ok=True)  # Ensure target directory exists\n",
    "\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.pdf', '.docx', '.pptx', '.xlsx')):\n",
    "                input_pdf_path = Path(root) / file\n",
    "                print(f\"Processing file: {input_pdf_path}\")\n",
    "                \n",
    "                # Step 1: Convert PDF to Markdown\n",
    "                md_filename = get_pdf_markdown(input_pdf_path, target_dir)\n",
    "                \n",
    "                # Step 2: Split the Markdown content (assume method available)\n",
    "                md_header_splits = get_markdown_splits(md_filename)\n",
    "                \n",
    "                # Step 3: Enrich the document (assume method available)\n",
    "                enriched_content = enrich_document_with_image(md_header_splits)\n",
    "                \n",
    "                # Step 4: Save enriched content\n",
    "                enriched_output_path = target_dir / f\"{Path(md_filename).stem}_enriched.md\"\n",
    "                with open(enriched_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(enriched_content)\n",
    "\n",
    "    print(f\"Processing complete. Enriched content saved to: {output_dir}\")\n",
    "\n",
    "# Example Usage\n",
    "input_dir = r\"../00 Dataset/docs\"\n",
    "output_dir = r\"../00 Dataset/markdown\"\n",
    "process_and_enrich_documents(input_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
